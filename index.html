<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transcribe Your Audio</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            font-family: sans-serif;
            background-color: #f0f4f8;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            margin: 0;
        }
        .container {
            background-color: #ffffff;
            border-radius: 0.75rem;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            padding: 2rem;
            width: 100%;
            max-width: 28rem;
            position: relative;
        }
        .decibel-bar {
            width: 100%;
            height: 8px;
            background-color: #e5e7eb;
            border-radius: 4px;
            overflow: hidden;
            margin-top: 8px;
        }
        .decibel-fill {
            height: 100%;
            background: linear-gradient(90deg, #10b981, #fbbf24, #ef4444);
            width: 0%;
            transition: width 0.1s ease;
        }
        .loading-overlay {
            position: absolute;
            top:0; left:0; right:0; bottom:0;
            background: rgba(255,255,255,0.7);
            backdrop-filter: blur(4px);
            display:flex;
            flex-direction:column;
            align-items:center;
            justify-content:center;
            border-radius:0.75rem;
            z-index:10;
            opacity:0;
            visibility:hidden;
            transition:0.3s;
        }
        .loading-overlay.visible {
            opacity:1;
            visibility:visible;
        }
        .spinner {
            border:4px solid rgba(0,0,0,0.1);
            border-left-color:#000;
            border-radius:50%;
            width:32px;
            height:32px;
            animation:spin 1s linear infinite;
        }
        @keyframes spin { to { transform:rotate(360deg); } }
    </style>
</head>
<body>

<div class="container">

    <p id="yan-name-top"
       class="text-center text-purple-700 text-sm font-medium mb-4 mt-4 hidden">
        I'm Yan! Try calling my name.
    </p>

    <h2 class="text-2xl font-bold text-center mb-6">Transcribe Your Audio</h2>

    <p id="recording-status" class="text-gray-600 text-sm text-center mb-2">
        Initializing microphone...
    </p>

    <p id="timer" class="text-xl font-mono text-gray-700 text-center">00:00</p>

    <div class="decibel-bar">
        <div id="decibel-fill" class="decibel-fill"></div>
    </div>

    <p id="decibel-display" class="text-sm text-gray-600 mt-2 text-center">Decibels: 0 dB</p>
    <p id="silence-counter" class="text-xs text-gray-500 mt-1 text-center">Silence: 0s</p>

    <div class="mt-4">
        <label class="block text-gray-700 text-sm mb-1">Yan's Reply</label>
        <audio id="audio-player" controls class="w-full"></audio>
    </div>

    <div id="loading-overlay" class="loading-overlay">
        <div class="spinner"></div>
        <p id="loading-text" class="mt-4 text-gray-700">Processing...</p>
    </div>
</div>

<script>

/* ===================================================================
   Persistent Device Session ID
=================================================================== */
function getOrCreateSessionId() {
    let id = localStorage.getItem("device_session_id");
    if (!id) {
        id = crypto.randomUUID();
        localStorage.setItem("device_session_id", id);
    }
    return id;
}
const DEVICE_SESSION_ID = getOrCreateSessionId();

/* ===================================================================
   Elements
=================================================================== */
const yanNameTop       = document.getElementById("yan-name-top");
const recordingStatus  = document.getElementById("recording-status");
const timerEl          = document.getElementById("timer");
const decibelFill      = document.getElementById("decibel-fill");
const decibelDisplay   = document.getElementById("decibel-display");
const silenceCounter   = document.getElementById("silence-counter");
const audioPlayer      = document.getElementById("audio-player");
const loadingOverlay   = document.getElementById("loading-overlay");
const loadingText      = document.getElementById("loading-text");

/* ===================================================================
   Constants
=================================================================== */
const WEBHOOK_URL       = "http://localhost:5678/webhook-test/audio-to-transcribe";
const SOUND_THRESHOLD   = 30;
const SILENCE_THRESHOLD = 35;
const SILENCE_DURATION  = 0.4;
const MIN_RECORDING_TIME= 0.4;
const LOW_VOLUME_FILTER = 30;

/* ===================================================================
   State
=================================================================== */
let stream = null;
let audioContext = null;
let microphone = null;
let analyser = null;
let mediaRecorder = null;
let audioChunks = [];
let recordedAudioBlob = null;
let timerInterval = null;
let seconds = 0;
let isRecording = false;
let silenceTimer = 0;
let micPaused = false;
let detectionInterval = null;

/* ===================================================================
   Helpers
=================================================================== */
const formatTime = t => {
    const m = Math.floor(t/60).toString().padStart(2,'0');
    const s = Math.floor(t%60).toString().padStart(2,'0');
    return `${m}:${s}`;
};

const showLoading = msg => {
    loadingText.textContent = msg;
    loadingOverlay.classList.add("visible");
};
const hideLoading = () => loadingOverlay.classList.remove("visible");

const updateTimer = () => {
    seconds++;
    timerEl.textContent = formatTime(seconds);
};

const getDecibels = () => {
    if (!analyser || micPaused) return -100;
    const dataArray = new Uint8Array(analyser.frequencyBinCount);
    analyser.getByteFrequencyData(dataArray);
    let sum = 0;
    for (let i = 0; i < dataArray.length; i++) sum += dataArray[i] ** 2;
    const rms = Math.sqrt(sum / dataArray.length);
    return 20 * Math.log10(rms || 0.01);
};

const updateDecibelDisplay = dB => {
    decibelDisplay.textContent = `Decibels: ${dB.toFixed(1)} dB`;
    const pct = Math.min(Math.max((dB + 100) / 100 * 100, 0), 100);
    decibelFill.style.width = pct + "%";
};

/* ===================================================================
   Pause / Resume Microphone
=================================================================== */
function pauseMicInput() {
    if (microphone && analyser && !micPaused) {
        try { microphone.disconnect(analyser); } catch {}
        micPaused = true;
    }
}

function resumeMicInput() {
    if (microphone && analyser && micPaused) {
        try { microphone.connect(analyser); } catch {}
        micPaused = false;
        recordingStatus.textContent = "Listening for sound...";
    }
}

/* ===================================================================
   Auto Recording Logic
=================================================================== */
function startRecording() {
    if (!stream || isRecording || micPaused) return;

    audioChunks = [];
    mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm" });

    mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
    mediaRecorder.onstop = () => {
        recordedAudioBlob = new Blob(audioChunks, { type: "audio/webm" });
        sendToWebhook();
    };

    silenceTimer = 0;
    seconds = 0;
    timerEl.textContent = "00:00";

    mediaRecorder.start();
    isRecording = true;
    recordingStatus.textContent = "Recording...";
    timerInterval = setInterval(updateTimer, 1000);

    monitorSilence();
}

function stopRecording() {
    if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
    }
    isRecording = false;
    clearInterval(timerInterval);
}

/* ===================================================================
   Detect Silence -> Auto Stop
=================================================================== */
function monitorSilence() {
    const loop = setInterval(() => {
        if (!isRecording) {
            clearInterval(loop);
            return;
        }
        const dB = getDecibels();
        updateDecibelDisplay(dB);

        if (dB < SILENCE_THRESHOLD) {
            silenceTimer += 0.1;
            silenceCounter.textContent = `Silence: ${silenceTimer.toFixed(1)}s`;
            if (silenceTimer >= SILENCE_DURATION && seconds >= MIN_RECORDING_TIME) {
                clearInterval(loop);
                stopRecording();
            }
        } else {
            silenceTimer = 0;
            silenceCounter.textContent = "Silence: 0s";
        }
    }, 100);
}

/* ===================================================================
   SEND AUDIO TO WEBHOOK
=================================================================== */
async function sendToWebhook() {
    if (!recordedAudioBlob) return;

    pauseMicInput();
    recordingStatus.textContent = "Yan is thinking...";
    showLoading("Yan is thinking...");

    // always hide hint before making a request
    yanNameTop.classList.add("hidden");

    const formData = new FormData();
    formData.append("audio_file", recordedAudioBlob, "audio.webm");
    formData.append("session_id", DEVICE_SESSION_ID);

    let webhookResponded = false;

    try {
        const response = await fetch(WEBHOOK_URL, {
            method: "POST",
            body: formData,
        });

        webhookResponded = true;

        const contentType = response.headers.get("content-type") || "";

        /* ======================================================
           CASE 1 — AUDIO: Yan replied correctly
        ======================================================= */
        if (contentType.startsWith("audio/")) {
            const replyBlob = await response.blob();
            audioPlayer.src = URL.createObjectURL(replyBlob);
            audioPlayer.autoplay = true;

            recordingStatus.textContent = "Yan is replying...";
        }

        /* ======================================================
           CASE 2 — ANYTHING ELSE:
            - text
            - json
            - error string
            - empty
            - wrong content type
           → Show “Call Yan” label
        ======================================================= */
        else {
            yanNameTop.classList.remove("hidden");   // ⭐ DISPLAY LABEL
            recordingStatus.textContent = "Listening for sound...";
            resumeMicInput();
        }
    }

    catch (err) {
        console.error("Webhook error:", err);

        // also show label on error
        yanNameTop.classList.remove("hidden");
        resumeMicInput();
    }

    hideLoading();
    isRecording = false;
    silenceTimer = 0;
    seconds = 0;

    // if no audio reply, mic is already resumed
    if (!audioPlayer.src) {
        resumeMicInput();
    }
}


/* ===================================================================
   AUDIO PLAYER EVENTS
=================================================================== */
audioPlayer.addEventListener("play", () => {
    recordingStatus.textContent = "Yan is replying...";
    pauseMicInput();

    /* ⭐ OPTION A: HIDE TOP LABEL WHEN YAN STARTS REPLYING */
    yanNameTop.classList.add("hidden");
});

audioPlayer.addEventListener("ended", () => {
    resumeMicInput();
});

/* ===================================================================
   Main Listening Loop
=================================================================== */
function startListeningLoop() {
    if (detectionInterval) return;

    detectionInterval = setInterval(() => {
        if (isRecording || micPaused) return;

        const dB = getDecibels();
        updateDecibelDisplay(dB);

        if (dB > LOW_VOLUME_FILTER && dB > SOUND_THRESHOLD) {
            startRecording();
        }
    }, 100);
}

/* ===================================================================
   Initialize Microphone
=================================================================== */
async function initMic() {
    try {
        recordingStatus.textContent = "Requesting microphone...";
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        audioContext = new AudioContext();
        microphone   = audioContext.createMediaStreamSource(stream);
        analyser     = audioContext.createAnalyser();
        analyser.fftSize = 256;
        microphone.connect(analyser);

        recordingStatus.textContent = "Listening for sound...";
        startListeningLoop();

    } catch (err) {
        alert("Microphone access denied.");
        console.error(err);
    }
}

document.addEventListener("DOMContentLoaded", initMic);

</script>

</body>
</html>
